{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,_), (X_test,_)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.astype('float32')/float(X_train.max())\n",
    "X_test=X_test.astype('float32')/float(X_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set :  (60000, 28, 28)\n",
      "Testing set :  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set : \",X_train.shape)\n",
    "print(\"Testing set : \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set :  (60000, 784)\n",
      "Testing set :  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping our images into matrices\n",
    "X_train=X_train.reshape((len(X_train),np.prod(X_train.shape[1:])))\n",
    "X_test=X_test.reshape((len(X_test),np.prod(X_test.shape[1:])))\n",
    "print(\"Training set : \",X_train.shape) #The resolution has changed\n",
    "print(\"Testing set : \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0722 15:35:55.508080 140135687452480 deprecation_wrapper.py:119] From /home/deep/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0722 15:35:55.552881 140135687452480 deprecation_wrapper.py:119] From /home/deep/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0722 15:35:55.564037 140135687452480 deprecation_wrapper.py:119] From /home/deep/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0722 15:35:55.616487 140135687452480 deprecation_wrapper.py:119] From /home/deep/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0722 15:35:55.659392 140135687452480 deprecation_wrapper.py:119] From /home/deep/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0722 15:35:55.678694 140135687452480 deprecation.py:323] From /home/deep/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0722 15:35:55.976757 140135687452480 deprecation_wrapper.py:119] From /home/deep/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.2780 - val_loss: 0.1922\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1728 - val_loss: 0.1549\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.1454 - val_loss: 0.1348\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1290 - val_loss: 0.1213\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.1179 - val_loss: 0.1122\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1105 - val_loss: 0.1062\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1054 - val_loss: 0.1019\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1017 - val_loss: 0.0990\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0992 - val_loss: 0.0967\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0974 - val_loss: 0.0953\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0962 - val_loss: 0.0944\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0954 - val_loss: 0.0937\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0948 - val_loss: 0.0933\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.0945 - val_loss: 0.0929\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0942 - val_loss: 0.0928\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0938 - val_loss: 0.0924\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0937 - val_loss: 0.0923\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.0936 - val_loss: 0.0922\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0935 - val_loss: 0.0923\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0931 - val_loss: 0.0920\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0928 - val_loss: 0.0918\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0927 - val_loss: 0.0915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73954e3358>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim=X_train.shape[1]\n",
    "encoding_dim=32\n",
    "compression_factor=float(input_dim/encoding_dim)\n",
    " \n",
    "autoencoder=Sequential()\n",
    "autoencoder.add(Dense(encoding_dim, input_shape=(input_dim,),activation='relu'))\n",
    "autoencoder.add(Dense(input_dim,activation='sigmoid'))\n",
    " \n",
    "input_img=Input(shape=(input_dim,))\n",
    "encoder_layer=autoencoder.layers[0]\n",
    "encoder=Model(input_img,encoder_layer(input_img))\n",
    " \n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train,X_train,epochs=50, batch_size=256, shuffle=True, validation_data=(X_test,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# creating a 600 x 600 pixels canvas for mouse drawing\n",
    "canvas = np.ones((600,600), dtype=\"uint8\") * 255\n",
    "# designating a 400 x 400 pixels point of interest on which digits will be drawn\n",
    "canvas[100:500,100:500] = 0\n",
    "\n",
    "start_point = None\n",
    "end_point = None\n",
    "is_drawing = False\n",
    "\n",
    "def draw_line(img,start_at,end_at):\n",
    "    cv2.line(img,start_at,end_at,255,15)\n",
    "\n",
    "def on_mouse_events(event,x,y,flags,params):\n",
    "    global start_point\n",
    "    global end_point\n",
    "    global canvas\n",
    "    global is_drawing\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if is_drawing:\n",
    "            start_point = (x,y)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if is_drawing:\n",
    "            end_point = (x,y)\n",
    "            draw_line(canvas,start_point,end_point)\n",
    "            start_point = end_point\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        is_drawing = False\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Test Canvas\")\n",
    "cv2.setMouseCallback(\"Test Canvas\", on_mouse_events)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    cv2.imshow(\"Test Canvas\", canvas)\n",
    "    key = cv2.waitKey(1) & 0xFF \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('s'):\n",
    "        is_drawing = True\n",
    "    elif key == ord('c'):\n",
    "        canvas[100:500,100:500] = 0\n",
    "    elif key == ord('p'):\n",
    "        image = canvas[100:500,100:500]\n",
    "        input = cv2.resize(image, (28 , 28)).reshape((28 , 28,1)).astype('float32') / 255\n",
    "        test_case=np.array([input])\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 400), (1, 28, 28, 1))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape,test_case.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case=test_case.reshape((len(test_case),np.prod(test_case.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded=encoder.predict(test_case)\n",
    "decoder=autoencoder.predict(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_case.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFEAAABRCAYAAACqj0o2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAB7klEQVR4nO3cwW2DMBjF8c9VJ0DquRc2oCtkimSY7AJbMAMjcOg9zOCeHEXIqQr92wbyfqeKVAY9PYOBKM57b/I/b6UP4AgUIkAhAhQiQCEC3pf8s3Nu1aW8aZqnnw3DsGbIUm7e+4/5RrdkibM2xN/24ZxbM2Qpg/f+a75xURPXmgf1GOo84J2FamY6JyIUIiDLdJ6LTdkwrWPnz61PcTURUKSJMXu++KiJgM00cW5P5001EbDZJsaEtlVVdd82TZOZlT1vqokAhQgoMp3P5/P9767rShwCSk0EZG1ibGkyjqOZmdV1nfNQUGoiYDMPIPZMTQQoRIBCBChEwGbvna/X66rPSlATAVneOwdhX49LHPqrfYmXT9H3zmoioMg58bF9VHPCmKfTyczM+r5Hxv0LNRGgEAGHuXcOY8YuXqmpiYCsTczZjhQXr2fURMDhQnTOZX9eebgQS1CIAIUIUIgAhQhQiICXCLFtW2vbNtn4LxFialmfbOeU6LZPT7ZTUYgAhQhQiIDNvrxfKixhLpdL9n2riYAsTcz52zslvvuoJgIUIqDIzxccjZoIUIgAhQhQiACFCFCIAIUIUIgAhQhQiIClt303M/tOcSA78RnbuOhtn8RpOgMUIkAhAhQiQCECFCJAIQIUIkAhAn4AOiJ3e06I5RgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1296x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADEAAABRCAYAAAB7aE5GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABsklEQVRoge2bsWrCUBSGb4qYRRwEV+to9iDoJIKTD+C7iG/gU7j5GI4OOji4uHUIJDSKiDgFbrdAa+4pB0r79/J/4/09cD5O8JCQBNZa8995+esGfgJKoEAJFGqqH9dqNgxDZx5FkVh/Op3EvNlsinmSJLm1tv3Ul1j1hTAMxUZ3u51YPx6PxXwymYj5fD5/qzr34nKiBAqUQMELCdVf7OPxMPv93pl3Oh2xvigKMb9cLpp2SryYBCVQoAQKlEBBtScajYaJ49iZ3+93sb7dfroV+ES/3xfzw+FQee7FJCiBAiVQoAQKqj3RarXMbDZz5sPhUKzfbDZivt1uNe2UeDEJSqBACRQogYJqT6RpapbLpTP/7rnR7XYT88VioWmnxItJUAIFSqBACRTUz50Gg4Ezv16vYv35fBbzLMs07ZR4MQlKoEAJFCiBgmpPFEVh8jwXc4npdCrm6/Va006JF5OgBAqUQIESKKj2RL1eN91u15n3ej2xfrVaifloNBLz4/FYee7FJCiBAiVQoAQKgebrriAI3o0xla///xKvVd9PqCRQ8eJyogQKlECBEihQAoUPvjNfcgdup/AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFEAAABRCAYAAACqj0o2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEcUlEQVR4nO2cuU4jQRCGP3Of4gaBkBAEgCBBYkWEyHkOQl6KAIkXgBcgQUJaEZBBwnIf5hL3ORusaro9Hixbrhmzu/Ultqab8aj4u/vvqrYzQRBglEdVpR/gX8CCqIAFUQELogIWRAVqSumcyWT+96U8GwRBT/SiKbE0fsVdtCAqYEFUwIKogAVRAQuiAiVZnCTJZDIA1NbW5rW9v78DIMmSqir3v5drn5+fST/il5gSFaiIEkV1ANXV1QA0NTUB0NLSAkB7e3vYZ3JyEoC5uTkAmpubw7a1tTUA1tfXAbi6ugLg4+MjkWePw5SoQMXnRFFia2srAENDQwAMDw+HfUZHRwGnTunrt21vbwNwc3MDmBL/OiyICmRKqbGUm8WRBUWGMLiFpK+vD3DD8Pb2Nuzz9vaW0+YvTGJtXl5egHw7pMzPIAh+RC+aEhVIZWGJKrCxsTFsa2hoAODi4gKA+/t7wKkPCqtK7l3JqqUpUYFUlCjbNNnS+UqUOe3u7g7IVWAxfIe6uSlRAQuiAokNZ9+GyHCur68HcnccDw8PQHFZGLlnTU3+YydsbQpiSlQgMSX6ihCVxalEFCRqjVOkKK+jowOAzs7OsO3k5ARw1ijNPbNgSlQgFYsj6np9fQXg+fk5r03UJooUEw4wNjYGwPT0NOCMObiszdPTE+DU7s/Jci36qoUpUYFUlBitg4hqwKlT+oghb2trC/vIap7NZoHcea+7uxtwiQzh8fExfC/Z7uhnaWFKVMCCqECq+URZPHyzLENThnpczlEWm7q6OiB30enp+XNIa35+HoDZ2VkANjc3wz5LS0uAs0NllFctn5gUqRaqoqqDr22HmHAfWZAk4wPOLom6R0ZGALeIgCux+rZHE1OiAqkqUcvs+kqW7d7KygrgrI0cBgA3p8qr9tbQlKiABVGBip+AKBcZmkdHRwCsrq4CMDU1FfaRRUcskr9oaexeTIkKVPxUmLyP2o84Q1xINaJIKXR1dXWFbePj4wBcXl4CuVkkjUXGlKhAqkqMU53YjmgR3j8NKxTKkMu8JznHhYWFsG1vbw+Ag4MDwGWDwJT4bUj1GElUdfC1uuLUKq9+X+k3MDAAwOLiIgAzMzNhn8HBQQCWl5dz7qOFKVEBC6ICiQ1nf8jIpC+pf38yj6bso0Pf/3sZ+r79kXuKjZEDAqenp2GfjY0NAHZ2dvI+XwNTogKJZbb9L/VIMam/vx/IPQV7fn4OOAMcp0RBFOQ/s2TA5d5yYN7PjO/u7gJwdnYGuFO10XsVgWW2kyKVYyRyHnFiYgLI/TKPzFNihKUw75c8Cx1Wkrb9/X0ADg8PgXgbVcisl4MpUQELogKJDWc/Z3d8fAzA1tYWAL29vWGbLBbX19eAK0KVWtaMsz9pYUpUINXivXefvGvf4QB7EZjFSYqKZLb/EtUVjSlRAQuiAhZEBSyIClgQFbAgKlCqxcnyxc/f/ScMxV0sacdixGPDWQELogIWRAUsiApYEBWwICpgQVTAgqiABVGB3/h77K0cEyVlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,4))\n",
    "   #plot input image\n",
    "ax=plt.subplot(3,1,1)\n",
    "plt.imshow(test_case.reshape(28,28))\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "# plot encoded image\n",
    "ax = plt.subplot(3, 1, 1)\n",
    "plt.imshow(encoded.reshape(8, 4))\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "     # plot reconstructed image\n",
    "ax = plt.subplot(3, 1,1)\n",
    "plt.imshow(decoder.reshape(28, 28))\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
